{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ad02117-7870-4001-8f53-428e397da8e6",
   "metadata": {},
   "source": [
    "# Clone the Data from Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce346b-b8b1-4ccb-83f1-d553a6dc6a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "url = \"https://github.com/PhonePe/pulse/archive/refs/heads/main.zip\"\n",
    "response = requests.get(url)\n",
    "\n",
    "with zipfile.ZipFile(BytesIO(response.content)) as zip_ref:\n",
    "    zip_ref.extractall(\"your directory\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4183f67-fc58-4ac5-8687-cc5d868369e3",
   "metadata": {},
   "source": [
    "# Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19fd981-f5ba-4e80-831d-97abd3b456f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"C:\\\\Users\\\\rahul\\\\Data Science\\\\pulse-master\\\\data\\\\map\\\\insurance\\\\country\\\\india\\\\state\\\\jharkhand\\\\2024\\\\1.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Explore it\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2b6e5f-4edd-45a3-86bf-c512df87bce3",
   "metadata": {},
   "source": [
    "# Convert the json Data to csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132588e2-078e-4d70-bdde-375cb32ac377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "Base_path = Path(r\"C:\\Users\\rahul\\Data Science\\pulse-master\\data\")\n",
    "OUTPUT_DIR = Path(r\"C:\\Users\\rahul\\Data Science\\pulse-master\\csv_output\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True) \n",
    "\n",
    "# Containers for each CSV\n",
    "agg_transactions = []\n",
    "agg_users = []\n",
    "agg_insurance = []\n",
    "map_transactions = []\n",
    "map_users = []\n",
    "map_insurance_hover = []\n",
    "map_insurance_country = []\n",
    "top_transactions = []\n",
    "top_users = []\n",
    "top_insurance = []\n",
    "\n",
    "def extract_meta (parts):\n",
    "    \"\"\"Extract year, quarter, location, level from file path parts.\"\"\"\n",
    "    section = parts[0] #agrregated/map/top\n",
    "    subtype = parts[1] #transcation/user/top\n",
    "    level = parts[-4]  #country/state\n",
    "    location = parts[-3] #india/state name\n",
    "    year =  parts[-2] # it return the year e.g 2018 or else none\n",
    "    quarter = parts[-1].replace(\".json\",\"\") #we are repacing the extension of json to text\n",
    "\n",
    "    return section,subtype,level,location,year,quarter\n",
    "\n",
    "\n",
    "#walk trough each json file\n",
    "for json_file in Base_path.rglob(\"*.json\"):\n",
    "    try:\n",
    "        with open(json_file,\"r\",encoding = \"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"❌ could not read {json_file}\")\n",
    "        continue\n",
    "\n",
    "    parts = json_file.relative_to(Base_path).parts\n",
    "    section,subtype,level,location,year,quarter = extract_meta(parts)\n",
    "\n",
    "     # === Aggregated ===\n",
    "    if section == \"aggregated\":\n",
    "        if subtype == \"transaction\":\n",
    "            for entry in data[\"data\"].get(\"transactionData\",[]):\n",
    "                for pi in entry.get(\"paymentInstruments\",[]):\n",
    "                    agg_transactions.append({\n",
    "                        \"year\":year,\n",
    "                        \"quarter\": quarter,\n",
    "                        \"country_state_level\": level,\n",
    "                        \"location\": location,\n",
    "                        \"category\": entry.get(\"name\"),\n",
    "                        \"transaction_count\": pi.get(\"count\"),\n",
    "                        \"transaction_amount\": pi.get(\"amount\")\n",
    "                    })\n",
    "        \n",
    "        elif subtype == \"user\":\n",
    "            aggregated = data[\"data\"].get(\"aggregated\",[])\n",
    "            devices = data[\"data\"].get(\"usersByDevice\",[])\n",
    "            # Case 1: If devices is a list -> loop normally\n",
    "            if isinstance(devices,list):\n",
    "                for device in devices:\n",
    "                    agg_users.append({\n",
    "                        \"year\":year,\n",
    "                        \"quarter\": quarter,\n",
    "                        \"country_state_level\": level,\n",
    "                        \"location\": location,\n",
    "                        \"registered_users\": aggregated.get(\"registeredUsers\"),\n",
    "                        \"app_opens\": aggregated.get(\"appOpens\"),\n",
    "                        \"brand\": device.get(\"brand\"),\n",
    "                        \"brand_count\": device.get(\"count\"),\n",
    "                        \"brand_percentage\": device.get(\"percentage\")\n",
    "                })\n",
    "\n",
    "            # Case 2: If devices is None -> still save aggregated data (without brand info)\n",
    "            else:\n",
    "                 agg_users.append({\n",
    "                     \"year\": year,\n",
    "                     \"quarter\": quarter,\n",
    "                     \"country_state_level\": level,\n",
    "                     \"location\": location,\n",
    "                     \"registered_users\": aggregated.get(\"registeredUsers\"),\n",
    "                     \"app_opens\": aggregated.get(\"appOpens\"),\n",
    "                     \"brand\": \"Unknown\",\n",
    "                     \"brand_count\": 0,\n",
    "                     \"brand_percentage\": 0\n",
    "                 })\n",
    "\n",
    "        elif subtype == \"insurance\":\n",
    "            for entry in data[\"data\"].get(\"transactionData\",[]):\n",
    "                for pi in entry.get(\"paymentInstruments\",[]):\n",
    "                    agg_insurance.append({\n",
    "                        \"year\":year,\n",
    "                        \"quarter\": quarter,\n",
    "                        \"country_state_level\": level,\n",
    "                        \"location\": location,\n",
    "                        \"transaction_count\": pi.get(\"count\"),\n",
    "                        \"transaction_amount\": pi.get(\"amount\")\n",
    "                    })\n",
    "\n",
    "    #  === Map ===\n",
    "    elif section == \"map\":\n",
    "        if subtype == \"transaction\":\n",
    "            for entry in data[\"data\"].get(\"hoverDataList\",[]):\n",
    "                for metric in entry.get(\"metric\",[]):\n",
    "                    map_transactions.append({\n",
    "                        \"year\":year,\n",
    "                        \"quarter\": quarter,\n",
    "                        \"country_state_level\": level,\n",
    "                        \"location\": location,\n",
    "                        \"district\": entry.get(\"name\"),\n",
    "                        \"transaction_count\": metric.get(\"count\"),\n",
    "                        \"transaction_amount\": metric.get(\"amount\")\n",
    "                    })\n",
    "\n",
    "        elif subtype == \"user\":\n",
    "            for name,vals in data[\"data\"].get(\"hoverData\",{}).items():\n",
    "                map_users.append({\n",
    "                    \"year\": year,\n",
    "                    \"quarter\": quarter,\n",
    "                    \"country_state_level\": level,\n",
    "                    \"location\": location,\n",
    "                    \"registeredUsers\": vals.get(\"registeredUsers\"),\n",
    "                    \"app_opens\": vals.get(\"appOpens\")\n",
    "                })\n",
    "\n",
    "        elif subtype == \"insurance\":\n",
    "            # Case 1: lat/lng/metric/label format (columns + data)\n",
    "            if \"columns\" in data.get(\"data\", {}).get(\"data\", {}):\n",
    "                for row in data[\"data\"][\"data\"].get(\"data\", []):\n",
    "                    if len(row) == 4:\n",
    "                        lat, lng, metric, label = row\n",
    "                        map_insurance_hover.append({\n",
    "                            \"year\": year,\n",
    "                            \"quarter\": quarter,\n",
    "                            \"country_state_level\": level,\n",
    "                            \"location\": location,\n",
    "                            \"lat\": lat,\n",
    "                            \"lng\": lng,\n",
    "                            \"metric\": metric,\n",
    "                            \"label\": label\n",
    "                        })\n",
    "\n",
    "            elif \"hoverDataList\" in data.get(\"data\", {}):\n",
    "                for entry in data[\"data\"].get(\"hoverDataList\", []):\n",
    "                    name = entry.get(\"name\")\n",
    "                    for metric in entry.get(\"metric\", []):\n",
    "                         map_insurance_country.append({\n",
    "                             \"year\": year,\n",
    "                             \"quarter\": quarter,\n",
    "                             \"country_state_level\": level,\n",
    "                             \"location\": location,\n",
    "                             \"district\": name,\n",
    "                             \"transaction_count\": metric.get(\"count\"),\n",
    "                             \"transaction_amount\": metric.get(\"amount\")\n",
    "                         })\n",
    "\n",
    "    # === Top ===\n",
    "    elif section == \"top\":\n",
    "        if subtype == \"transaction\":\n",
    "            for group_name in [\"states\",\"districts\",\"pincodes\"]:\n",
    "                for entry in data[\"data\"].get(group_name) or []:\n",
    "                    metric = entry.get(\"metric\",{})\n",
    "                    top_transactions.append({\n",
    "                        \"year\":year,\n",
    "                        \"quarter\": quarter,\n",
    "                        \"country_state_level\": level,\n",
    "                        \"location\": location,\n",
    "                        \"state_dis_pin\": group_name[:-1],  # remove plural\n",
    "                        \"state_dis_pin_name\": entry.get(\"entityName\"),\n",
    "                        \"transaction_count\": metric.get(\"count\"),\n",
    "                        \"transaction_amount\": metric.get(\"amount\")\n",
    "                    })\n",
    "\n",
    "        elif subtype == \"user\":\n",
    "            for group_name in [\"states\", \"districts\", \"pincodes\"]:\n",
    "                 for entry in data[\"data\"].get(group_name) or []:\n",
    "                      top_users.append({\n",
    "                          \"year\":year,\n",
    "                          \"quarter\": quarter,\n",
    "                          \"country_state_level\": level,\n",
    "                          \"location\": location,\n",
    "                          \"state_dis_pin\": group_name[:-1],  # remove plural\n",
    "                          \"state_dis_pin_name\": entry.get(\"name\"),\n",
    "                          \"registeredUsers\": entry.get(\"registeredUsers\") \n",
    "\n",
    "                      })\n",
    "\n",
    "        elif subtype == \"insurance\":\n",
    "            data_dict = data.get(\"data\",{})\n",
    "            if isinstance(data_dict, dict):\n",
    "                for group_name in [\"states\", \"districts\", \"pincodes\"]:\n",
    "                    for entry in data_dict.get(group_name) or []:\n",
    "                        metric = entry.get(\"metric\", {})\n",
    "                        top_insurance.append({\n",
    "                            \"year\":year,\n",
    "                            \"quarter\": quarter,\n",
    "                            \"country_state_level\": level,\n",
    "                            \"location\": location,\n",
    "                            \"state_dis_pin\": group_name[:-1],  # remove plural\n",
    "                            \"state_dis_pin_name\": entry.get(\"entityName\"),\n",
    "                            \"transaction_count\": metric.get(\"count\"),\n",
    "                            \"transaction_amount\": metric.get(\"amount\")\n",
    "                     })\n",
    "                     \n",
    "                         \n",
    "# === Save all CSVs ===\n",
    "pd.DataFrame(agg_transactions).to_csv(OUTPUT_DIR / \"aggregated_transactions.csv\", index=False)\n",
    "pd.DataFrame(agg_users).to_csv(OUTPUT_DIR / \"aggregated_users.csv\", index=False)\n",
    "pd.DataFrame(agg_insurance).to_csv(OUTPUT_DIR / \"aggregated_insurance.csv\", index=False)\n",
    "pd.DataFrame(map_transactions).to_csv(OUTPUT_DIR / \"map_transactions.csv\", index=False)\n",
    "pd.DataFrame(map_users).to_csv(OUTPUT_DIR / \"map_users.csv\", index=False)\n",
    "pd.DataFrame(map_insurance_hover).to_csv(OUTPUT_DIR / \"map_insurance_hover.csv\", index=False)\n",
    "pd.DataFrame(map_insurance_country).to_csv(OUTPUT_DIR / \"map_insurance_country.csv\", index=False)\n",
    "pd.DataFrame(top_transactions).to_csv(OUTPUT_DIR / \"top_transactions.csv\", index=False)\n",
    "pd.DataFrame(top_users).to_csv(OUTPUT_DIR / \"top_users.csv\", index=False)\n",
    "pd.DataFrame(top_insurance).to_csv(OUTPUT_DIR / \"top_insurance.csv\", index=False)\n",
    "\n",
    "print(\"✅ All CSV files created in:\", OUTPUT_DIR.resolve())\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e53f928-882c-45ae-a511-1f8ed77e95a8",
   "metadata": {},
   "source": [
    "# Create the tables in Sql Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418b34ae-a210-4e92-9831-bbaaa4eb4760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "db_config = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"root\",\n",
    "    \"database\": \"phonepe_pulse\"\n",
    "}\n",
    "\n",
    "conn = mysql.connector.connect(**db_config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "query = [\n",
    "    \"\"\"CREATE TABLE aggregated_transactions (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        year INT,\n",
    "        quarter INT,\n",
    "        country_state_level VARCHAR(100),\n",
    "        location VARCHAR(100),\n",
    "        category VARCHAR(50),         -- recharge, p2p, merchant, etc.\n",
    "        transaction_count BIGINT,\n",
    "        transaction_amount BIGINT\n",
    "    );\"\"\",\n",
    "    \n",
    "    \"\"\"CREATE TABLE aggregated_insurance (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        year INT,\n",
    "        quarter INT,\n",
    "        country_state_level VARCHAR(100),\n",
    "        location VARCHAR(100),\n",
    "        transaction_count BIGINT,\n",
    "        transaction_amount BIGINT\n",
    "    );\"\"\",\n",
    "    \n",
    "    \"\"\"CREATE TABLE aggregated_users (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        year INT,\n",
    "        quarter INT,\n",
    "        country_state_level VARCHAR(100),\n",
    "        location VARCHAR(100),\n",
    "        registered_users BIGINT,\n",
    "        app_opens BIGINT,\n",
    "        brand VARCHAR(50),\n",
    "        brand_count BIGINT,\n",
    "        brand_percentage DECIMAL(12,9)\n",
    "    );\"\"\",\n",
    "    \n",
    "    \"\"\"CREATE TABLE map_transactions (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        year INT,\n",
    "        quarter INT,\n",
    "        country_state_level VARCHAR(100),\n",
    "        location VARCHAR(100),\n",
    "        district VARCHAR(100),\n",
    "        transaction_count BIGINT,\n",
    "        transaction_amount BIGINT\n",
    "    );\"\"\",\n",
    "    \n",
    "    \"\"\"CREATE TABLE map_users (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        year INT,\n",
    "        quarter INT,\n",
    "        country_state_level VARCHAR(100),\n",
    "        location VARCHAR(100),\n",
    "        registeredUsers BIGINT,\n",
    "        app_opens BIGINT\n",
    "    );\"\"\",\n",
    "    \n",
    "    \"\"\"CREATE TABLE map_insurance_country (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        year INT,\n",
    "        quarter INT,\n",
    "        country_state_level VARCHAR(100),\n",
    "        location VARCHAR(100),\n",
    "        district VARCHAR(100),\n",
    "        transaction_count BIGINT,\n",
    "        transaction_amount BIGINT\n",
    "    );\"\"\",\n",
    "    \n",
    "    \"\"\"CREATE TABLE map_insurance_hover (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        year INT,\n",
    "        quarter INT,\n",
    "        country_state_level VARCHAR(100),\n",
    "        location VARCHAR(100),\n",
    "        district VARCHAR(100),\n",
    "        lat DOUBLE,\n",
    "        lng DOUBLE,\n",
    "        metric BIGINT\n",
    "    );\"\"\",\n",
    "    \n",
    "    \"\"\"CREATE TABLE top_transactions (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        year INT,\n",
    "        quarter INT,\n",
    "        country_state_level VARCHAR(100),\n",
    "        location VARCHAR(100),\n",
    "        state_dis_pin VARCHAR(20),      -- district/pincode\n",
    "        state_dis_pin_name VARCHAR(100),     -- district name or pincode\n",
    "        transaction_count BIGINT,\n",
    "        transaction_amount BIGINT\n",
    "    );\"\"\",\n",
    "    \n",
    "    \"\"\"CREATE TABLE top_insurance (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        year INT,\n",
    "        quarter INT,\n",
    "        country_state_level VARCHAR(100),\n",
    "        location VARCHAR(100),\n",
    "        state_dis_pin VARCHAR(20),      -- district/pincode\n",
    "        state_dis_pin_name VARCHAR(100),\n",
    "        transaction_count BIGINT,\n",
    "        transaction_amount BIGINT\n",
    "    );\"\"\",\n",
    "    \n",
    "    \"\"\"CREATE TABLE top_users (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        year INT,\n",
    "        quarter INT,\n",
    "        country_state_level VARCHAR(100),\n",
    "        location VARCHAR(100),\n",
    "        state_dis_pin VARCHAR(20),      -- district/pincode\n",
    "        state_dis_pin_name VARCHAR(100),\n",
    "        registeredUsers BIGINT\n",
    "    );\"\"\"\n",
    "]\n",
    "\n",
    "for q in query:\n",
    "    cursor.execute(q)\n",
    "\n",
    "print(\"✅ Tables created successfully!\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db9ca6b-d919-41b6-b76e-7500e9f7799f",
   "metadata": {},
   "source": [
    "# To upload the csv data in table, created in sql Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147fb08d-6759-4459-8356-738d8fd64915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "def insert_csv_to_mysql(csv_path, table_name, db_config):\n",
    "    \"\"\"\n",
    "    Insert CSV data into a MySQL table safely, handling NULLs correctly.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to MySQL\n",
    "        conn = mysql.connector.connect(**db_config)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Load CSV\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Convert NaN/NaT to None (MySQL NULL)\n",
    "        df = df.where(pd.notnull(df), None)\n",
    "\n",
    "        # Get actual table columns from MySQL\n",
    "        cursor.execute(f\"DESCRIBE {table_name}\")\n",
    "        table_columns = [col[0] for col in cursor.fetchall()]\n",
    "\n",
    "        # Keep only common columns\n",
    "        common_cols = [col for col in df.columns if col in table_columns]\n",
    "        if not common_cols:\n",
    "            print(f\"⚠️ No matching columns for {table_name}. Skipping.\")\n",
    "            return\n",
    "\n",
    "        df = df[common_cols]\n",
    "\n",
    "        # Build query dynamically\n",
    "        columns = \", \".join([f\"`{col}`\" for col in common_cols])\n",
    "        placeholders = \", \".join([\"%s\"] * len(common_cols))\n",
    "        insert_query = f\"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})\"\n",
    "\n",
    "        # Replace all NaN/NaT with None again (important for executemany)\n",
    "        data = [tuple(None if pd.isna(x) else x for x in row) for row in df.to_numpy()]\n",
    "\n",
    "        # Bulk insert\n",
    "        batch_size = 5000\n",
    "        for i in range(0, len(data), batch_size):\n",
    "            cursor.executemany(insert_query, data[i:i+batch_size])\n",
    "\n",
    "        # Commit\n",
    "        conn.commit()\n",
    "        print(f\"✅ {len(df)} rows from {csv_path} inserted into {table_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error with {csv_path}: {e}\")\n",
    "\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "# ---------- USAGE ----------\n",
    "\n",
    "db_config = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"root\",\n",
    "    \"database\": \"phonepe_pulse\"\n",
    "}\n",
    "\n",
    "# aggregated_transactions\n",
    "insert_csv_to_mysql(\n",
    "    csv_path=\"C:/Users/rahul/Data Science/pulse-master/csv_output/aggregated_transactions.csv\",\n",
    "    table_name=\"aggregated_transactions\",\n",
    "    db_config=db_config\n",
    ")\n",
    "\n",
    "# aggregated_insurance\n",
    "insert_csv_to_mysql(\n",
    "    csv_path=\"C:/Users/rahul/Data Science/pulse-master/csv_output/aggregated_insurance.csv\",\n",
    "    table_name=\"aggregated_insurance\",\n",
    "    db_config=db_config\n",
    ")\n",
    "\n",
    "# aggregated_users\n",
    "insert_csv_to_mysql(\n",
    "    csv_path=\"C:/Users/rahul/Data Science/pulse-master/csv_output/aggregated_users.csv\",\n",
    "    table_name=\"aggregated_users\",\n",
    "    db_config=db_config\n",
    ")\n",
    "# map_insurance_country\n",
    "insert_csv_to_mysql(\n",
    "    csv_path=\"C:/Users/rahul/Data Science/pulse-master/csv_output/map_insurance_country.csv\",\n",
    "    table_name=\"map_insurance_country\",\n",
    "    db_config=db_config\n",
    ")\n",
    "\n",
    "# map_insurance_hover\n",
    "insert_csv_to_mysql(\n",
    "    csv_path=\"C:/Users/rahul/Data Science/pulse-master/csv_output/map_insurance_hover.csv\",\n",
    "    table_name=\"map_insurance_hover\",\n",
    "    db_config=db_config\n",
    ")\n",
    "\n",
    "# map_transactions\n",
    "insert_csv_to_mysql(\n",
    "    csv_path=\"C:/Users/rahul/Data Science/pulse-master/csv_output/map_transactions.csv\",\n",
    "    table_name=\"map_transactions\",\n",
    "    db_config=db_config\n",
    ")\n",
    "\n",
    "# map_users\n",
    "insert_csv_to_mysql(\n",
    "    csv_path=\"C:/Users/rahul/Data Science/pulse-master/csv_output/map_users.csv\",\n",
    "    table_name=\"map_users\",\n",
    "    db_config=db_config\n",
    ")\n",
    "\n",
    "# top_insurance\n",
    "insert_csv_to_mysql(\n",
    "    csv_path=\"C:/Users/rahul/Data Science/pulse-master/csv_output/top_insurance.csv\",\n",
    "    table_name=\"top_insurance\",\n",
    "    db_config=db_config\n",
    ")\n",
    "\n",
    "# top_transactions\n",
    "insert_csv_to_mysql(\n",
    "    csv_path=\"C:/Users/rahul/Data Science/pulse-master/csv_output/top_transactions.csv\",\n",
    "    table_name=\"top_transactions\",\n",
    "    db_config=db_config\n",
    ")\n",
    "\n",
    "# top_users\n",
    "insert_csv_to_mysql(\n",
    "    csv_path=\"C:/Users/rahul/Data Science/pulse-master/csv_output/top_users.csv\",\n",
    "    table_name=\"top_users\",\n",
    "    db_config=db_config\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
